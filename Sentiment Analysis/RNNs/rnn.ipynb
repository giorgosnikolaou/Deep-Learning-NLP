{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX4IpI8CBDLE"
      },
      "source": [
        "### Importing essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LciaCTNaBDLE",
        "outputId": "272617d9-7d6c-4da0-b8d2-906c5f7c2eae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/giorgo/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/giorgo/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/giorgo/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/giorgo/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/home/giorgo/anaconda3/envs/ai2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 700) \n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.ioff()\n",
        "%matplotlib agg\n",
        "# !pip install seaborn\n",
        "import seaborn as sns\n",
        "import random, os\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch import nn\n",
        "from torch.nn import Sequential, Module, ModuleList, Linear, Dropout\n",
        "from torch.nn import ReLU, LeakyReLU, Sigmoid, GELU\n",
        "from torch.optim import SGD, Adam, Adamax\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR, LinearLR\n",
        "# !pip install torchmetrics\n",
        "from torchmetrics import F1Score, Precision, Recall, Accuracy, ConfusionMatrix\n",
        "\n",
        "# !pip install torchtext\n",
        "import torchtext\n",
        "\n",
        "# !pip install colorama\n",
        "from colorama import init, Fore, Style\n",
        "init(autoreset=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQC634dNBDLG"
      },
      "source": [
        "### Google Drive and Relative Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rSEYjZvBDLH",
        "outputId": "ac1b374f-e556-41c5-84ac-7482065b4d95"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# ROOT = 'gdrive/My Drive/ai2_data/2/'  \n",
        "ROOT = './'\n",
        "\n",
        "DATASETS     = ROOT + 'datasets/'\n",
        "VECTORIZERS  = ROOT + 'vectorizers/'\n",
        "GLOVE        = ROOT + 'glove/'\n",
        "SAVED_MODELS = ROOT + 'saved_models/'\n",
        "PLOTS        = ROOT + 'plots/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Vx-yhlBDLI"
      },
      "source": [
        "### Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wcd09pL-BDLI"
      },
      "outputs": [],
      "source": [
        "MAX_VECTORS = 50000\n",
        "def write_data(path, obj):\n",
        "    with open(path, 'wb') as file:\n",
        "        pickle.dump(obj, file)\n",
        "\n",
        "def load_data(path):\n",
        "    return pd.read_pickle(path)\n",
        "\n",
        "def load_csv(path, sep='\\t'):\n",
        "    return pd.read_csv(path, sep=sep)\n",
        "\n",
        "def prepare_emb(dim=300):\n",
        "    glove = torchtext.vocab.GloVe(name=\"6B\", dim=300, max_vectors=MAX_VECTORS)\n",
        "    glove.vectors = torch.cat([glove.vectors, torch.zeros(1,300)], dim=0)\n",
        "    return glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwOMwq9lBDLJ"
      },
      "source": [
        "### Reviews Cleanup and Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hajcjrs2BDLK"
      },
      "outputs": [],
      "source": [
        "def clean_df(df, glove_path):\n",
        "    df['new_rating'] = df['rating'] >= 7\n",
        "\n",
        "    sw = stopwords.words('english') \n",
        "\n",
        "    sw.append('movie')\n",
        "    sw.append('film')\n",
        "    sw.append('br')\n",
        "    \n",
        "    sw.remove('not')\n",
        "    sw.remove('no')\n",
        "\n",
        "    sw = set(sw)\n",
        "\n",
        "    df['clean_review'] = df['review'].str.lower()\n",
        "    df['clean_review'] = df['clean_review'].str.replace('n\\'t', ' not')\n",
        "    df['clean_review'] = df['clean_review'].str.replace(r'(@\\S+)|(#\\S+)|(http\\S+)|(www.\\S+)', ' ', regex=True)\n",
        "    df['clean_review'] = df['clean_review'].str.replace(r'[^a-z]', ' ', regex=True)\n",
        "    df['clean_review'] = df['clean_review'].map(lambda x: ' '.join([word for word in word_tokenize(x) if not word in sw]))\n",
        "\n",
        "    glove = pd.read_pickle(glove_path)\n",
        "    \n",
        "    def emb(input):\n",
        "        return np.array([glove.stoi[word] for word in input.split() if word in glove.stoi])\n",
        "    \n",
        "    df['emb_review'] = df['clean_review'].apply(emb)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j51_MHz9XJ-Q"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vhgVn-QBXJ-Q"
      },
      "outputs": [],
      "source": [
        "class ClassifierData(Dataset):\n",
        "    def __init__(self, dataset, x_label='emb_review', y_label='new_rating', device='cpu', load=True):\n",
        "        df = load_data(dataset) if load else dataset\n",
        "\n",
        "        self.inputs = [torch.from_numpy(x).to(device) for x in df[x_label].values]\n",
        "\n",
        "        self.labels = [1. if i == True else 0. for i in df[y_label].values]\n",
        "        self.labels = torch.tensor(self.labels).to(device)\n",
        "        self.labels = self.labels.unsqueeze(1)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.inputs[index], self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JE7zO3NlXJ-R"
      },
      "outputs": [],
      "source": [
        "def get_datasets(path, device='cpu'):\n",
        "    train = ClassifierData(path + 'train.pkl', device=device)\n",
        "    val   = ClassifierData(path + 'val.pkl', device=device)\n",
        "    test  = ClassifierData(path + 'test.pkl', device=device)\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cBZ4sZXKXJ-R"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "\n",
        "def collate(batch):\n",
        "    (xs, ys) = zip(*batch)\n",
        "    return (pad_sequence(xs, batch_first=True, padding_value=MAX_VECTORS), [len(x) for x in xs]), torch.stack(list(ys)).to(device)\n",
        "\n",
        "def get_dataloaders(train_data, val_data, test_data, batch_size, device='cuda'):\n",
        "    device = device\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNeFwBrsXJ-S"
      },
      "source": [
        "### Train & Test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uvI7_kRfXJ-S"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "\n",
        "    samples = len(dataloader)\n",
        "    loss = 0.0\n",
        "    predicted, target = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (X, lens), y in dataloader:\n",
        "            pred = model(X, lens)\n",
        "            # loss += loss_fn(pred, y).item()\n",
        "            loss += loss_fn(pred, y).item()\n",
        "       \n",
        "            predicted.append(pred)             \n",
        "            target.append(y)             \n",
        "    \n",
        "    predicted = torch.cat(predicted, dim=0).to(device)\n",
        "    target = torch.cat(target, dim=0).to(device)\n",
        "\n",
        "    p = Precision(task=\"binary\", num_classes=2).to(device)\n",
        "    r = Recall(task=\"binary\", num_classes=2).to(device)\n",
        "    f1 = F1Score(task=\"binary\", num_classes=2).to(device)\n",
        "    acc = Accuracy(task=\"binary\", num_classes=2).to(device)\n",
        "\n",
        "    p  =  p(predicted, target).item()\n",
        "    r  =  r(predicted, target).item()\n",
        "    f1 = f1(predicted, target).item()\n",
        "\n",
        "    return loss / samples, p, r, f1, acc(predicted, target).item(), predicted.detach().cpu().numpy(), target.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch(model, t, dataloader, loss_fn, optimizer, clip, show_epochs, scheduler, pass_loss, val_dataloader):\n",
        "    model.train()\n",
        "    batches = len(dataloader)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    if show_epochs:\n",
        "        print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "    predicted, target = [], []\n",
        "\n",
        "    for (X, lens), y in dataloader:\n",
        "        pred = model(X, lens)   \n",
        "    \n",
        "        predicted.append(pred)             \n",
        "        target.append(y)         \n",
        "\n",
        "        # loss = loss_fn(pred, y)\n",
        "        loss = loss_fn(pred, y)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if clip:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip) # Clip gradients\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    if scheduler:\n",
        "        if pass_loss:\n",
        "            scheduler.step(loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "    \n",
        "    epoch_loss = running_loss / batches  \n",
        "    \n",
        "    predicted = torch.cat(predicted, dim=0).to(device)\n",
        "    target = torch.cat(target, dim=0).to(device)\n",
        "    f1 = F1Score(task=\"binary\", num_classes=2).to(device)\n",
        "    \n",
        "    if show_epochs and not val_dataloader:\n",
        "        print(f\"\\nEpoch Average Loss: {epoch_loss:>7f}\\n\")\n",
        "    \n",
        "    \n",
        "    return epoch_loss, f1(predicted, target).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5QFqWStgXJ-S"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, epochs, loss_fn, optimizer, val_dataloader=None, show_epochs=False, device='cpu', **kwargs):\n",
        "    scheduler = kwargs['scheduler'] if 'scheduler' in kwargs else None\n",
        "    pass_loss = kwargs['pass_loss'] if 'pass_loss' in kwargs else False\n",
        "    patience = kwargs['patience'] if 'patience' in kwargs else None \n",
        "    clip = kwargs['clip'] if 'clip' in kwargs else None\n",
        "\n",
        "    if not patience:\n",
        "        patience = epochs\n",
        "    else:\n",
        "        assert(val_dataloader)\n",
        "\n",
        "    min_loss = float('inf')\n",
        "    last_change = 0\n",
        "\n",
        "    metrics = {'loss' : {'train' : [], 'test' : []}, \n",
        "               'f1' : {'train' : [], 'test' : []}}\n",
        "\n",
        "    for t in range(epochs):\n",
        "        epoch_loss, f1_score = epoch(model, t, dataloader, loss_fn, optimizer, clip, show_epochs, scheduler, pass_loss, val_dataloader)\n",
        "        metrics['loss']['train'].append(epoch_loss)\n",
        "        metrics['f1']['train'].append(f1_score)\n",
        "\n",
        "        if val_dataloader:\n",
        "            val_loss, _, _, f1, _, _, _ = test(val_dataloader, model, loss_fn, device)\n",
        "            \n",
        "            if show_epochs:\n",
        "                print(f'Loss on train set     : {epoch_loss}')\n",
        "                print(f'Loss on validation set: {val_loss}')\n",
        "                print(f'F1-score on validation set: {f1*100:>.2f}')\n",
        "\n",
        "            last_change += 1\n",
        "\n",
        "            metrics['loss']['test'].append(val_loss)\n",
        "            metrics['f1']['test'].append(f1)\n",
        "\n",
        "            if val_loss < min_loss:\n",
        "                write_data(f'{SAVED_MODELS}model_{device}.pth', model)\n",
        "                min_loss = val_loss\n",
        "                last_change = 0\n",
        "            \n",
        "            if patience < last_change:\n",
        "                if show_epochs:\n",
        "                    print(f'No improvement on the validation loss for {last_change} > {patience} (patience) epochs.')\n",
        "                    print(f'Stopping training after [{t+1:>2d}/{epochs:>2d}] epochs.')\n",
        "                break\n",
        "\n",
        "    return metrics\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfcKA2kEXJ-S"
      },
      "source": [
        "### Complete pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg_GLNQpA0E0"
      },
      "source": [
        "#### Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wi5Divjn_7cG"
      },
      "outputs": [],
      "source": [
        "def torch_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTyQO7-2CBdJ"
      },
      "source": [
        "#### Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hv3Mbte0AP-d"
      },
      "outputs": [],
      "source": [
        "# Based on: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
        "\n",
        "def helper(train, test, xlabel, ylabel, f1=False, id=None):\n",
        "    fig, axes = plt.subplots(1, 1, figsize=(8,5))\n",
        "\n",
        "    axes.set_xlabel('Epoch')\n",
        "    axes.set_ylabel('F1-Score' if f1 else 'Loss')\n",
        "\n",
        "    axes.grid()\n",
        "\n",
        "    epoch_step = len(train) // 20\n",
        "    if not epoch_step:\n",
        "        epoch_step = 1\n",
        "\n",
        "    xvalues = np.arange(1, len(train) + 1, epoch_step)\n",
        "\n",
        "    axes.plot(xvalues, train[::epoch_step], \"o-\", color=\"r\", label=xlabel)\n",
        "    axes.plot(xvalues, test[::epoch_step], \"o-\", color=\"g\", label=ylabel)\n",
        "\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    plt.xticks(np.arange(1, len(train) + epoch_step + 1, epoch_step))\n",
        "\n",
        "    max_stat = max(max(train), max(test)) \n",
        "    step = 0.05 if f1 else max_stat / 10\n",
        "    low = 0.50 if f1 else 0.\n",
        "    high = 1.01 if f1 else max_stat + step\n",
        "\n",
        "    plt.yticks(np.arange(low, high, step))\n",
        "\n",
        "    if id:\n",
        "        name = 'f1' if f1 else 'loss'\n",
        "        fig.savefig(f'{PLOTS}{name}/{id}_{name}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "    \n",
        "\n",
        "def learning_curve(metrics, id=None):\n",
        "    helper(np.array(metrics['f1']['train']), np.array(metrics['f1']['test']), 'Training F1-Score', 'Validation F1-Score', f1=True, id=id)\n",
        "    helper(np.array(metrics['loss']['train']), np.array(metrics['loss']['test']), 'Training loss', 'Validation loss', id=id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-4W7J9TCEPY"
      },
      "source": [
        "#### ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P6fJ2kPBAiBb"
      },
      "outputs": [],
      "source": [
        "def roc(target, pred, id=None):\n",
        "    fpr, tpr, _ = roc_curve(target, pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 1, figsize=(8,5))\n",
        "\n",
        "    axes.set_xlabel('False Positive Rate')\n",
        "    axes.set_ylabel('True Positive Rate')\n",
        "\n",
        "    axes.grid()\n",
        "\n",
        "    axes.plot(fpr, tpr, '.', color='r', label=f'ROC curve (AUC = {100 * roc_auc : .2f}%)')\n",
        "\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    ticks = np.arange(0, 1.05, 0.2)\n",
        "    plt.xticks(ticks)\n",
        "    plt.yticks(ticks)\n",
        "\n",
        "    if id:\n",
        "        fig.savefig(f'{PLOTS}/roc/{id}_roc.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qK_05FUCLEu"
      },
      "source": [
        "#### Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "43g7nWXFXJ-T"
      },
      "outputs": [],
      "source": [
        "def complete_pass(data_path, model, **kwargs):\n",
        "    # Data \n",
        "    batch_size = kwargs['batch_size'] if 'batch_size' in kwargs else 16\n",
        "\n",
        "    # Architecture\n",
        "    model_params = kwargs['model_params'] if 'model_params' in kwargs else {}\n",
        "\n",
        "    # Hyperparameters\n",
        "    device = kwargs['device'] if 'device' in kwargs else 'cpu'\n",
        "    epochs = kwargs['epochs'] if 'epochs' in kwargs else 30\n",
        "    \n",
        "    loss_fn = kwargs['loss_fn'] if 'loss_fn' in kwargs else nn.BCELoss()\n",
        "    lr = kwargs['lr'] if 'lr' in kwargs else 0.002\n",
        "\n",
        "    optimizer = kwargs['optimizer'] if 'optimizer' in kwargs else torch.optim.Adam\n",
        "    kwargs.pop('optimizer', None)\n",
        "    optimizer_params = kwargs['optimizer_params'] if 'optimizer_params' in kwargs else {}\n",
        "\n",
        "    scheduler = kwargs['scheduler'] if 'scheduler' in kwargs else None\n",
        "    scheduler_params = kwargs['scheduler_params'] if 'scheduler_params' in kwargs else {}\n",
        "    pass_loss = scheduler_params['pass_loss'] if 'pass_loss' in scheduler_params else False\n",
        "    patience = kwargs['patience'] if 'patience' in kwargs else None    \n",
        "\n",
        "\n",
        "    clip = kwargs['clip'] if 'clip' in kwargs else None\n",
        "\n",
        "    # Results\n",
        "    show_epochs = kwargs['show_epochs'] if 'show_epochs' in kwargs else False\n",
        "    cmatrix = kwargs['cmatrix'] if 'cmatrix' in kwargs else False\n",
        "    lc = kwargs['lc'] if 'lc' in kwargs else False\n",
        "    auroc = kwargs['auroc'] if 'auroc' in kwargs else False\n",
        "\n",
        "    validate = kwargs['validate'] if 'validate' in kwargs else False\n",
        "    reproducibility = kwargs['reproducibility'] if 'reproducibility' in kwargs else False\n",
        "\n",
        "    id = kwargs['id'] if 'id' in kwargs else None\n",
        "\n",
        "\n",
        "    if reproducibility:\n",
        "          torch_seed(seed=5)\n",
        "\n",
        "\n",
        "    train_data, val_data, test_data = get_datasets(data_path, device=device)\n",
        "    train_dataloader, val_dataloader, test_dataloader = get_dataloaders(train_data, val_data, test_data, batch_size)\n",
        "    \n",
        "    model = model(**model_params).to(device)\n",
        "\n",
        "    def count_parameters(model):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    if not id:\n",
        "        print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "    optimizer = optimizer(model.parameters(), lr=lr, **optimizer_params)\n",
        "\n",
        "    if scheduler:\n",
        "        if pass_loss:\n",
        "            scheduler_params = dict(scheduler_params)\n",
        "            del scheduler_params['pass_loss']\n",
        "\n",
        "        scheduler = scheduler(optimizer, **scheduler_params)\n",
        "\n",
        "    start_time = time.perf_counter()\n",
        "    metrics = train(train_dataloader, model, epochs, loss_fn, optimizer, val_dataloader=val_dataloader if validate else None,\n",
        "                    show_epochs=show_epochs, device=device, pass_loss=pass_loss, patience=patience, scheduler=scheduler, clip=clip)\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    if validate:\n",
        "        model = load_data(f'{SAVED_MODELS}model_{device}.pth')\n",
        "\n",
        "    loss, p, r, f1, acc, pred, target = test(test_dataloader, model, loss_fn, device)\n",
        "\n",
        "    res1 = f'\\nTime taken: {end_time - start_time:>0.2f}'\n",
        "    res2 = f'Avg loss: {loss:>8f}\\tAccuracy: {(100*acc):>0.2f}%'\n",
        "    res3 = f'Precision: {(100*p):>0.2f}%\\tRecall: {(100*r):>0.2f}%\\t\\tF1-Score: {(100*f1):>0.2f}%'\n",
        "\n",
        "    if id:\n",
        "        with open('results.txt', 'a') as file:\n",
        "            desc = model.get_desc()\n",
        "            desc += f'Clip range           : ({-clip}, {clip})\\n'\n",
        "            desc += f'Trainable Parameters : {count_parameters(model):,}\\n'\n",
        "            desc += f'Batch size           : {batch_size}\\n'\n",
        "            desc += f'Optimizer            : Adam\\n'\n",
        "            desc += f'Optimizer Parameters : {optimizer_params}\\n'\n",
        "            desc += f'Scheduler            : {scheduler}\\n'\n",
        "            desc += f'Scheduler Parameters : {scheduler_params}\\n'\n",
        "            desc += f'Patience             : {patience}\\n'\n",
        "\n",
        "            file.write(f'Model ID : {id}\\n{desc}\\nResults:\\n{res1}\\t{res2}\\n{res3}\\n\\n\\n')\n",
        "    \n",
        "    print(f'Model ID : {id}{res1}\\t{res2}\\n{res3}')\n",
        "\n",
        "    if lc:\n",
        "        learning_curve(metrics, id)\n",
        "\n",
        "    if auroc:\n",
        "        roc(target, pred, id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5UIfSO79AOR1"
      },
      "source": [
        "### Neural Networks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feed Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3gqmRQ7JAQem"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(Module):\n",
        "    def __init__(self, in_dim, **kwargs):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        linear_layers = [in_dim] + (kwargs['layers'] if 'layers' in kwargs else []) + [1]\n",
        "        num_of_layers = len(linear_layers) - 1\n",
        "\n",
        "        activation = kwargs['activation'] if 'activation' in kwargs else None\n",
        "        dropout = kwargs['dropout'] if 'dropout' in kwargs else None\n",
        "\n",
        "        if dropout:\n",
        "            if type(dropout) != list:\n",
        "                dropout = [dropout] * num_of_layers\n",
        "\n",
        "            assert(len(dropout) == num_of_layers)\n",
        "\n",
        "        if activation:\n",
        "            if type(activation) != list:\n",
        "                activation = [activation] * num_of_layers\n",
        "\n",
        "            assert(len(activation) == num_of_layers)\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(num_of_layers):\n",
        "            if dropout:\n",
        "                self.layers.append(Dropout(dropout[i]))\n",
        "\n",
        "            self.layers.append(Linear(linear_layers[i], linear_layers[i + 1]))\n",
        "\n",
        "            if activation and i != num_of_layers - 1:\n",
        "                self.layers.append(activation[i]())   \n",
        "\n",
        "        self.layers.append(Sigmoid())     \n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "            \n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "NEG_INF = -1000000\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.dk = np.sqrt(hidden_size)\n",
        "    \n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "\n",
        "        # Q : N x 2h\n",
        "        # K : N x E x 2h\n",
        "        # V : N x E x 2h\n",
        "\n",
        "        Q = Q.unsqueeze(1)      # N x  1 x 2h\n",
        "        K = K.transpose(1,2)    # N x 2h x  E\n",
        "\n",
        "        attention = torch.bmm(Q, K) / self.dk   # N x 1 x E\n",
        "\n",
        "        if mask != None:\n",
        "            attention.masked_fill_(mask.view(attention.size()), NEG_INF)\n",
        "\n",
        "        attention = F.softmax(attention, -1)\n",
        "\n",
        "        context = torch.bmm(attention, V).squeeze(1) # N x 1 x 2h -> N x 2h\n",
        "\n",
        "        return context"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Recurrent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "    cells = { \"LSTM\" : nn.LSTM, \"GRU\"  : nn.GRU }\n",
        "\n",
        "    def __init__(self, glove_path, cell_type, emb_dim=300, hidden_size=50, stacked_rnns=2, dropout=0, \n",
        "                skip_connections=False, bidirectional=True, attention=False):\n",
        "\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        glove = pd.read_pickle(glove_path)\n",
        "\n",
        "        self.dropout = Dropout(dropout)\n",
        "        \n",
        "        assert(cell_type in self.cells)\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        self.emb_dim          = emb_dim\n",
        "        self.cell_type        = cell_type\n",
        "        self.device           = device\n",
        "        self.stacked_rnns     = stacked_rnns\n",
        "        self.bidirectional    = bidirectional\n",
        "        self.skip_connections = skip_connections\n",
        "        self.dropout          = Dropout(dropout)\n",
        "\n",
        "        self.rnns = nn.ModuleList()\n",
        "\n",
        "        self.h_size = hidden_size * (int(bidirectional) + 1)\n",
        "        \n",
        "        for i in range(stacked_rnns):\n",
        "            \n",
        "            dim = self.h_size if i > 0 else emb_dim\n",
        "\n",
        "            rnn = self.cells[cell_type](         \n",
        "                input_size=dim,                 # features for each time step\n",
        "                hidden_size=hidden_size,        # hidden units\n",
        "                num_layers = 1,                 # layers on our stacked RNN \n",
        "                bidirectional = bidirectional,  # bidirectional rnn\n",
        "                batch_first=True,               # (batch, time_step, input_size)\n",
        "            )\n",
        "\n",
        "            self.rnns.append(rnn)\n",
        "\n",
        "        self.out        = NeuralNetwork(self.h_size, dropout=dropout)\n",
        "        self.attention  = Attention(self.h_size) if attention else None\n",
        "    \n",
        "    def get_desc(self):\n",
        "        desc = f'Single {self.cell_type}{\" bidirectional\" if self.bidirectional else \"\"} cell'\n",
        "        \n",
        "        if self.stacked_rnns > 1:\n",
        "            desc = f'{self.stacked_rnns} stacked {self.cell_type}{\" bidirectional\" if self.bidirectional else \"\"} cells'\n",
        "        \n",
        "        desc += f' with {self.h_size} hidden layers\\n'\n",
        "\n",
        "        desc += f'Dropout              : {self.dropout}\\n'\n",
        "        desc += f'Attention            : {True if self.attention else False}\\n'\n",
        "        desc += f'Skip Connections     : {self.skip_connections}\\n'\n",
        "        return desc\n",
        "\n",
        "    def pack_padded(self, x, lens):\n",
        "        return pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=False)\n",
        "    \n",
        "    def pad_packed(self, r_out):\n",
        "        out, _ = pad_packed_sequence(r_out, batch_first=True)\n",
        "        return out\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "        \n",
        "        r_out = embedded\n",
        "        h_n = None\n",
        "\n",
        "        for i, rnn in enumerate(self.rnns):\n",
        "\n",
        "            if i + 1 < self.stacked_rnns:\n",
        "                r_out = self.dropout(r_out)\n",
        "\n",
        "            inp = self.pack_padded(r_out, lens)\n",
        "\n",
        "            rnn.flatten_parameters()\n",
        "            if self.cell_type == 'LSTM':\n",
        "                r, (h_n, c_n) = rnn(inp) \n",
        "            else:\n",
        "                r, h_n = rnn(inp)\n",
        "\n",
        "            r = self.pad_packed(r)\n",
        "\n",
        "            r_out = (r_out + r) / 2 if i > 0 and self.skip_connections else r\n",
        "        ffn_input = r_out[:,-1,:]\n",
        "        \n",
        "        if self.attention:              \n",
        "            ffn_input = torch.cat((h_n[-1,:,:], h_n[-2,:,:]), dim = 1).to(self.device) if self.bidirectional else h_n.squeeze(0)\n",
        "            ffn_input = self.attention(Q=ffn_input, K=r_out, V=r_out, mask=x == 0) # self attention         \n",
        "\n",
        "        return self.out(ffn_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='LT',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 15, 'gamma' : 0.1}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimenting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "write_data(GLOVE + 'emb.pkl', prepare_emb())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_csv(DATASETS + 'imdb-reviews.csv')\n",
        "df['movie_id'] = df['url'].rank(method='dense', ascending=False).astype(int)\n",
        "df = clean_df(df, GLOVE + 'emb.pkl')\n",
        "\n",
        "write_data(DATASETS + 'imdb-reviews_clean.pkl', df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(10)\n",
        "\n",
        "df = load_data(DATASETS + 'imdb-reviews_clean.pkl')\n",
        "\n",
        "ids = random.sample(range(max(df['movie_id']) + 1), 300)\n",
        "\n",
        "df_test = df[df['movie_id'].isin(ids)] \n",
        "df = df[~df['movie_id'].isin(ids)] \n",
        "write_data(DATASETS + 'um_train.pkl', df)\n",
        "write_data(DATASETS + 'um_test.pkl', df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_data(DATASETS + 'imdb-reviews_clean.pkl')\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=1, stratify=df['new_rating'].values)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=1, stratify=train_data['new_rating'].values)\n",
        "\n",
        "write_data(DATASETS + 'train.pkl', train_data)\n",
        "write_data(DATASETS + 'val.pkl', val_data)\n",
        "write_data(DATASETS + 'test.pkl', test_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean results.txt file\n",
        "open('./results.txt', 'w').close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L01\n",
            "Time taken: 73.52\tAvg loss: 0.288406\tAccuracy: 88.79%\n",
            "Precision: 89.50%\tRecall: 87.89%\t\tF1-Score: 88.69%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L01',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=10, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : False, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 64, 'stacked_rnns' : 1, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L02\n",
            "Time taken: 73.53\tAvg loss: 0.258037\tAccuracy: 89.48%\n",
            "Precision: 88.42%\tRecall: 90.87%\t\tF1-Score: 89.63%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L02',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=15, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 64, 'stacked_rnns' : 1, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observing the curves, we notice overfitting happening, which is the first problem we must tackle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L03\n",
            "Time taken: 41.93\tAvg loss: 0.263777\tAccuracy: 89.41%\n",
            "Precision: 88.89%\tRecall: 90.09%\t\tF1-Score: 89.49%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L03',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 64, 'stacked_rnns' : 1, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L04\n",
            "Time taken: 33.68\tAvg loss: 0.272143\tAccuracy: 88.78%\n",
            "Precision: 89.52%\tRecall: 87.85%\t\tF1-Score: 88.68%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L04',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 64, 'stacked_rnns' : 1, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L05\n",
            "Time taken: 50.83\tAvg loss: 0.271012\tAccuracy: 88.88%\n",
            "Precision: 88.74%\tRecall: 89.07%\t\tF1-Score: 88.90%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L05',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 1, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L06\n",
            "Time taken: 156.74\tAvg loss: 0.276541\tAccuracy: 88.99%\n",
            "Precision: 89.73%\tRecall: 88.07%\t\tF1-Score: 88.89%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L06',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 1, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L07\n",
            "Time taken: 158.09\tAvg loss: 0.313614\tAccuracy: 87.15%\n",
            "Precision: 87.06%\tRecall: 87.27%\t\tF1-Score: 87.17%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L07',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 1, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially, we try increasing the batch size, dropout, and hidden size while decreasing the learning rate to address the overfitting. \n",
        "\n",
        "With a learning rate of `1e-4`, we observe a reduction in overfitting, but it comes with a decrease in performance. \n",
        "\n",
        "Therefore, we try more complex models to improve performance while avoiding overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L08\n",
            "Time taken: 695.59\tAvg loss: 0.332228\tAccuracy: 86.48%\n",
            "Precision: 86.92%\tRecall: 85.90%\t\tF1-Score: 86.40%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L08',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L09\n",
            "Time taken: 1227.00\tAvg loss: 0.373562\tAccuracy: 84.80%\n",
            "Precision: 81.59%\tRecall: 89.89%\t\tF1-Score: 85.54%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L09',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 3, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We stack `2` and then `3` RNNs, which eliminates overfitting but also results in poor performance. \n",
        "\n",
        "We need to find a better learning rate to improve performance without overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L10\n",
            "Time taken: 691.37\tAvg loss: 0.295468\tAccuracy: 88.29%\n",
            "Precision: 88.76%\tRecall: 87.69%\t\tF1-Score: 88.22%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L10',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L11\n",
            "Time taken: 455.74\tAvg loss: 0.263240\tAccuracy: 89.56%\n",
            "Precision: 86.74%\tRecall: 93.40%\t\tF1-Score: 89.95%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L11',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L10_1\n",
            "Time taken: 503.88\tAvg loss: 0.297660\tAccuracy: 88.10%\n",
            "Precision: 85.19%\tRecall: 92.25%\t\tF1-Score: 88.58%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L10_1',\n",
        "              \n",
        "              device='cuda', lr=2e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We try various learning rates and finally find a good balance with a learning rate of `1e-5`, which produces a very nice curve (`L10`). However, the performance is still underwhelming, so we increase the learning rate, which results in overfitting (`L11`).\n",
        "\n",
        "We then attempt to balance the performance and overfitting by adjusting the learning rate, but it doesn't work well (`L10_1`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L12\n",
            "Time taken: 644.08\tAvg loss: 0.364870\tAccuracy: 87.79%\n",
            "Precision: 84.41%\tRecall: 92.71%\t\tF1-Score: 88.37%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L12',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 3, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L13\n",
            "Time taken: 979.57\tAvg loss: 0.356474\tAccuracy: 86.14%\n",
            "Precision: 83.69%\tRecall: 89.78%\t\tF1-Score: 86.63%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L13',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 3, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L14\n",
            "Time taken: 1137.85\tAvg loss: 0.356474\tAccuracy: 86.14%\n",
            "Precision: 83.69%\tRecall: 89.78%\t\tF1-Score: 86.63%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L14',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=4, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 3, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L15\n",
            "Time taken: 910.72\tAvg loss: 0.357312\tAccuracy: 85.76%\n",
            "Precision: 83.91%\tRecall: 88.49%\t\tF1-Score: 86.14%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L15',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : True, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 3, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having `3` stacked RNNs didn't seem to work, even with skip connections.\n",
        "\n",
        "Although we achieved no overfitting, the performance was disappointing compared to our best model yet (`L10`)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will try fixing `L11` using a learning rate optimizer\n",
        "\n",
        "We choose `StepLR` to decrease the learning rate after giving the model a chance to learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L16\n",
            "Time taken: 415.02\tAvg loss: 0.275130\tAccuracy: 89.60%\n",
            "Precision: 87.49%\tRecall: 92.43%\t\tF1-Score: 89.89%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L16',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 6, 'gamma' : 0.1}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L17\n",
            "Time taken: 411.64\tAvg loss: 0.275130\tAccuracy: 89.60%\n",
            "Precision: 87.49%\tRecall: 92.43%\t\tF1-Score: 89.89%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L17',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 6, 'gamma' : 0.05}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L18\n",
            "Time taken: 509.27\tAvg loss: 0.281484\tAccuracy: 89.27%\n",
            "Precision: 87.10%\tRecall: 92.20%\t\tF1-Score: 89.58%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L18',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 4, 'gamma' : 0.2}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resutls were dissapointing, could not stop the overffiting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now turn to the mechanism of self (scaled dot product) attention and experiment to see how well we can do by utilizing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L19\n",
            "Time taken: 820.27\tAvg loss: 0.451516\tAccuracy: 87.30%\n",
            "Precision: 84.90%\tRecall: 90.76%\t\tF1-Score: 87.73%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L19',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 4, 'gamma' : 0.2}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L20\n",
            "Time taken: 529.59\tAvg loss: 0.324400\tAccuracy: 89.42%\n",
            "Precision: 87.09%\tRecall: 92.58%\t\tF1-Score: 89.75%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L20',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 4, 'gamma' : 0.2}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L21\n",
            "Time taken: 303.16\tAvg loss: 0.422349\tAccuracy: 85.26%\n",
            "Precision: 83.48%\tRecall: 87.92%\t\tF1-Score: 85.64%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L21',\n",
        "              \n",
        "              device='cuda', lr=1e-3, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 1, 'gamma' : 0.1}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the beginning, the model showed signs of overfitting, so we attempted to address this issue. \n",
        "\n",
        "We tried using a scheduler to decrease the learning rate, but we eventually realized that this approach was not effective. \n",
        "\n",
        "Instead, we decided to simply decrease the initial learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L22\n",
            "Time taken: 1367.23\tAvg loss: 0.284269\tAccuracy: 88.31%\n",
            "Precision: 89.31%\tRecall: 87.05%\t\tF1-Score: 88.17%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L22',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=10,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L23\n",
            "Time taken: 1363.71\tAvg loss: 0.263074\tAccuracy: 89.20%\n",
            "Precision: 89.33%\tRecall: 89.05%\t\tF1-Score: 89.19%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L23',\n",
        "              \n",
        "              device='cuda', lr=7.5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=10,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L22_5\n",
            "Time taken: 1046.56\tAvg loss: 0.287097\tAccuracy: 88.27%\n",
            "Precision: 86.72%\tRecall: 90.38%\t\tF1-Score: 88.51%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L22_5',\n",
        "              \n",
        "              device='cuda', lr=6e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=10,\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With `L22`, we observe a similar behavior to that of `L10`. However, we wanted to see if we could do even better. \n",
        "\n",
        "By slightly increasing the learning rate in `L23`, we see some overfitting occurring, but early stopping helped prevent it from worsening. \n",
        "\n",
        "As a result, we obtain a very good model that performs approximately `0.5%` better than `L22` and exhibits minimal overfitting. Therefore, `L23` represents the best model thus far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L24\n",
            "Time taken: 1683.43\tAvg loss: 0.333761\tAccuracy: 87.05%\n",
            "Precision: 87.82%\tRecall: 86.03%\t\tF1-Score: 86.92%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L24',\n",
        "              \n",
        "              device='cuda', lr=7.5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=10,\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The attempt to prevent overfitting in `L23` by increasing dropout did not yield any improvement."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now test models with different clip rates and see if we can further improve performance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L25\n",
            "Time taken: 428.30\tAvg loss: 0.275130\tAccuracy: 89.60%\n",
            "Precision: 87.49%\tRecall: 92.43%\t\tF1-Score: 89.89%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L25',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=5,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 6, 'gamma' : 0.05}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the same results, which means that the gradients were already within the range of `(-5, 5)` and therefore clipping before did not have any impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L26\n",
            "Time taken: 432.84\tAvg loss: 0.274066\tAccuracy: 89.40%\n",
            "Precision: 86.91%\tRecall: 92.78%\t\tF1-Score: 89.75%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L26',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 6, 'gamma' : 0.05}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L27\n",
            "Time taken: 530.50\tAvg loss: 0.257111\tAccuracy: 89.70%\n",
            "Precision: 87.00%\tRecall: 93.36%\t\tF1-Score: 90.07%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L27',\n",
        "              \n",
        "              device='cuda', lr=5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L28\n",
            "Time taken: 722.04\tAvg loss: 0.262367\tAccuracy: 89.99%\n",
            "Precision: 87.93%\tRecall: 92.71%\t\tF1-Score: 90.26%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L28',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L29\n",
            "Time taken: 834.12\tAvg loss: 0.262367\tAccuracy: 89.99%\n",
            "Precision: 87.93%\tRecall: 92.71%\t\tF1-Score: 90.26%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L29',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L30\n",
            "Time taken: 600.90\tAvg loss: 0.271238\tAccuracy: 89.16%\n",
            "Precision: 86.73%\tRecall: 92.47%\t\tF1-Score: 89.51%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L30',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=0.5,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L31\n",
            "Time taken: 467.41\tAvg loss: 0.309736\tAccuracy: 87.45%\n",
            "Precision: 83.22%\tRecall: 93.82%\t\tF1-Score: 88.20%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L31',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 8, 'gamma' : 0.2}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L32\n",
            "Time taken: 827.70\tAvg loss: 0.262367\tAccuracy: 89.99%\n",
            "Precision: 87.93%\tRecall: 92.71%\t\tF1-Score: 90.26%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L32',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 15, 'gamma' : 0.1}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L32_5\n",
            "Time taken: 454.61\tAvg loss: 0.295778\tAccuracy: 87.85%\n",
            "Precision: 84.59%\tRecall: 92.56%\t\tF1-Score: 88.40%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L32_5',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L33\n",
            "Time taken: 1052.47\tAvg loss: 0.277182\tAccuracy: 88.87%\n",
            "Precision: 88.29%\tRecall: 89.63%\t\tF1-Score: 88.96%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L33',\n",
        "              \n",
        "              device='cuda', lr=7.5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L33\n",
            "Time taken: 1856.36\tAvg loss: 0.290034\tAccuracy: 88.01%\n",
            "Precision: 87.99%\tRecall: 88.05%\t\tF1-Score: 88.02%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L34',\n",
        "              \n",
        "              device='cuda', lr=2.5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L35\n",
            "Time taken: 1455.85\tAvg loss: 0.273719\tAccuracy: 88.80%\n",
            "Precision: 88.16%\tRecall: 89.65%\t\tF1-Score: 88.90%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L35',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : L36\n",
            "Time taken: 932.55\tAvg loss: 0.312180\tAccuracy: 88.28%\n",
            "Precision: 86.17%\tRecall: 91.20%\t\tF1-Score: 88.62%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='L36',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True, \n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that without attention, the model is able to learn quickly but early stopping is essential to avoid overfitting.\n",
        "\n",
        "With attention, we have managed to develop models that do not overfit and have excellent performance. Therefore, they should be preferred over their non-attention counterparts."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the effect weight decay (L2 loss) had with the GRU cells, I tried experimenting with it here, but unfortunately it didn't work just as well"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### GRU cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : G01\n",
            "Time taken: 81.82\tAvg loss: 0.297458\tAccuracy: 88.40%\n",
            "Precision: 88.61%\tRecall: 88.14%\t\tF1-Score: 88.37%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='G01',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : False, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 64, 'stacked_rnns' : 1, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : G02\n",
            "Time taken: 95.84\tAvg loss: 0.292253\tAccuracy: 88.77%\n",
            "Precision: 88.00%\tRecall: 89.78%\t\tF1-Score: 88.88%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='G02',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 64, 'stacked_rnns' : 1, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the same amount of overfitting, the bidirectional model achieves quite the better performance and thus we will continue with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : LOOOOO\n",
            "Time taken: 524.49\tAvg loss: 0.262575\tAccuracy: 89.34%\n",
            "Precision: 86.53%\tRecall: 93.18%\t\tF1-Score: 89.73%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='G03',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : LOOOOO\n",
            "Time taken: 486.61\tAvg loss: 0.285353\tAccuracy: 88.29%\n",
            "Precision: 88.50%\tRecall: 88.03%\t\tF1-Score: 88.26%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='G04',\n",
        "              \n",
        "              device='cuda', lr=1e-4, epochs=15, patience=2, batch_size=128,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : G05\n",
            "Time taken: 671.49\tAvg loss: 0.286509\tAccuracy: 88.26%\n",
            "Precision: 86.07%\tRecall: 91.29%\t\tF1-Score: 88.61%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='G05',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=15, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True, \n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : G06\n",
            "Time taken: 1071.73\tAvg loss: 0.269809\tAccuracy: 89.41%\n",
            "Precision: 87.91%\tRecall: 91.40%\t\tF1-Score: 89.62%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='G06',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True, \n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will stop here because `G06` is an excellent model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO3jPTDKZcJb"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unknown movies dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LdMTHA1oZcJb"
      },
      "outputs": [],
      "source": [
        "ROOT = './'\n",
        "\n",
        "DATASETS     = ROOT + 'datasets/'\n",
        "GLOVE        = ROOT + 'glove/'\n",
        "SAVED_MODELS = ROOT + 'saved_models/'\n",
        "PLOTS        = ROOT + 'plots/'\n",
        "\n",
        "TRAIN_PATH = DATASETS + 'um_train.pkl' # Should be the .csv file given to us\n",
        "TEST_PATH  = DATASETS + 'um_test.pkl' # Should be your hidden .csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "t51Y6FYJZcJd"
      },
      "outputs": [],
      "source": [
        "df_train = load_data(TRAIN_PATH)\n",
        "df_test  = load_data(TEST_PATH)\n",
        "\n",
        "train_data, val_data = train_test_split(df_train, test_size=0.2, random_state=1, stratify=df_train['new_rating'].values)\n",
        "\n",
        "write_data(DATASETS + 'train.pkl', train_data)\n",
        "write_data(DATASETS + 'val.pkl', val_data)\n",
        "write_data(DATASETS + 'test.pkl', df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : UM1\n",
            "Time taken: 534.28\tAvg loss: 0.290639\tAccuracy: 88.05%\n",
            "Precision: 88.04%\tRecall: 88.48%\t\tF1-Score: 88.26%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='UM1',\n",
        "              \n",
        "              device='cuda', lr=2.5e-4, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : False,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "\n",
        "              scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={'step_size' : 15, 'gamma' : 0.1}\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : UM2\n",
            "Time taken: 1064.92\tAvg loss: 0.337337\tAccuracy: 85.31%\n",
            "Precision: 85.73%\tRecall: 85.24%\t\tF1-Score: 85.49%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='UM2',\n",
        "              \n",
        "              device='cuda', lr=2.5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : UM3\n",
            "Time taken: 2106.41\tAvg loss: 0.278387\tAccuracy: 88.85%\n",
            "Precision: 88.66%\tRecall: 89.49%\t\tF1-Score: 89.07%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='UM3',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                                      },\n",
        "              clip=1,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ID : UM4\n",
            "Time taken: 1329.18\tAvg loss: 0.272945\tAccuracy: 89.14%\n",
            "Precision: 87.14%\tRecall: 92.22%\t\tF1-Score: 89.61%\n"
          ]
        }
      ],
      "source": [
        "complete_pass(data_path=DATASETS, validate=True, reproducibility=True, lc=True, auroc=True, id='UM4',\n",
        "              \n",
        "              device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=64,\n",
        "\n",
        "              model=RNN, model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                                        'bidirectional' : True, 'skip_connections' : False, 'attention' : True, \n",
        "                                        'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                                      },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Out of the models I have tested, all of them show minimal overfitting. However, I recommend using the models with attention for testing on your dataset. \n",
        "\n",
        "Based on my experiments, I expect that the model with the GRU cells and attention will perform the best. \n",
        "\n",
        "Overall, it seems that attention has proven to be a beneficial addition to the models."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pre-training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_best(data_path, model, id, **kwargs):\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam\n",
        "\n",
        "    # Architecture\n",
        "    model_params = kwargs['model_params'] if 'model_params' in kwargs else {}\n",
        "\n",
        "    # Hyperparameters\n",
        "    device = kwargs['device'] if 'device' in kwargs else 'cuda'\n",
        "    batch_size = kwargs['batch_size'] if 'batch_size' in kwargs else 16\n",
        "    epochs = kwargs['epochs'] if 'epochs' in kwargs else 30\n",
        "    lr = kwargs['lr'] if 'lr' in kwargs else 0.002\n",
        "    clip = kwargs['clip'] if 'clip' in kwargs else None\n",
        "    patience = kwargs['patience'] if 'patience' in kwargs else None\n",
        "\n",
        "    scheduler = kwargs['scheduler'] if 'scheduler' in kwargs else None\n",
        "    scheduler_params = kwargs['scheduler_params'] if 'scheduler_params' in kwargs else {}  \n",
        "\n",
        "    optimizer_params = kwargs['optimizer_params'] if 'optimizer_params' in kwargs else {}\n",
        "\n",
        "    torch_seed(seed=5)\n",
        "\n",
        "\n",
        "    df = load_data(data_path)\n",
        "    train_data, val_data = train_test_split(df, test_size=0.2, random_state=1, stratify=df['new_rating'].values)\n",
        "\n",
        "    train_data, val_data = ClassifierData(train_data, load=False, device=device), ClassifierData(val_data, load=False, device=device)\n",
        "    \n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "    \n",
        "    \n",
        "    model = model(**model_params).to(device)\n",
        "\n",
        "    optimizer = optimizer(model.parameters(), lr=lr, **optimizer_params)\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler = scheduler(optimizer, **scheduler_params)\n",
        "\n",
        "    metrics = train(train_dataloader, model, epochs, loss_fn, optimizer, device=device, scheduler=scheduler, clip=clip, \n",
        "                                                                   val_dataloader=val_dataloader, patience=patience)\n",
        "    \n",
        "    write_data(f'{SAVED_MODELS}{id}.pkl', load_data(f'{SAVED_MODELS}model_{device}.pth'))\n",
        "\n",
        "    learning_curve(metrics, id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_best( data_path=DATASETS + 'imdb-reviews_clean.pkl', model=RNN, id='lstm',\n",
        "              \n",
        "            device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=256,\n",
        "\n",
        "            model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'LSTM', \n",
        "                           'bidirectional' : True, 'skip_connections' : False, 'attention' : True,\n",
        "                           'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.4\n",
        "                        },\n",
        "            clip=1,\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_best( data_path=DATASETS + 'imdb-reviews_clean.pkl', model=RNN, id='gru',\n",
        "              \n",
        "            device='cuda', lr=5e-5, epochs=30, patience=2, batch_size=64,\n",
        "\n",
        "            model_params={ 'glove_path' : GLOVE + 'emb.pkl', 'emb_dim' : 300, 'cell_type' : 'GRU', \n",
        "                           'bidirectional' : True, 'skip_connections' : False, 'attention' : True, \n",
        "                           'hidden_size' : 128, 'stacked_rnns' : 2, 'dropout' : 0.8\n",
        "                        },\n",
        "              clip=1,\n",
        "              optimizer_params={'weight_decay' : 1e-4}\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = './'\n",
        "\n",
        "DATASETS = ROOT + 'datasets/'\n",
        "VECTORIZERS = ROOT + ''\n",
        "GLOVE = ROOT + ''\n",
        "SAVED_MODELS = ROOT + 'saved_models/'\n",
        "\n",
        "GRU  = SAVED_MODELS + 'gru.pkl'    # Should be the .pkl file of one provided pre-trained model\n",
        "LSTM = SAVED_MODELS + 'lstm.pkl'   # Should be the .pkl file of one provided pre-trained model\n",
        "TEST_PATH  = DATASETS + 'imdb-reviews.csv' # Should be your hidden .csv file\n",
        "\n",
        "write_data(GLOVE + 'emb.pkl', prepare_emb())\n",
        "\n",
        "\n",
        "df_test  = load_csv(TEST_PATH)\n",
        "\n",
        "df_test  = clean_df(df_test, GLOVE + 'emb.pkl')\n",
        "\n",
        "data = ClassifierData(df_test, device='cuda', load=False)\n",
        "loader = DataLoader(data, batch_size=64, shuffle=False, collate_fn=collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg loss: 0.212785\n",
            "Accuracy  : 91.61%\tF1-Score  : 91.66%\n",
            "Precision : 91.15%\tRecall    : 92.17%\n"
          ]
        }
      ],
      "source": [
        "model = load_data(LSTM)\n",
        "\n",
        "loss, p, r, f1, acc, _, _ = test(loader, model, nn.BCELoss(), 'cuda')\n",
        "\n",
        "print(f'Avg loss: {loss:>8f}\\n{\"Accuracy\":10s}: {(100*acc):>0.2f}%\\t{\"F1-Score\":10s}: {(100*f1):>0.2f}%')\n",
        "print(f'{\"Precision\":10s}: {(100*p):>0.2f}%\\t{\"Recall\":10s}: {(100*r):>0.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_data(GRU)\n",
        "\n",
        "loss, p, r, f1, acc, _, _ = test(loader, model, nn.BCELoss(), 'cuda')\n",
        "\n",
        "print(f'Avg loss: {loss:>8f}\\n{\"Accuracy\":10s}: {(100*acc):>0.2f}%\\t{\"F1-Score\":10s}: {(100*f1):>0.2f}%')\n",
        "print(f'{\"Precision\":10s}: {(100*p):>0.2f}%\\t{\"Recall\":10s}: {(100*r):>0.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ai2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "05e291d52689d8f30625a1e02d932abe1fddef6008045c8089f2e366dd54d624"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
